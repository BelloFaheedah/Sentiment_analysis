---
title: "A Sentiment Analysis Model in R"
output: html_notebook
---

*Sentiment Analysis* is a machine learning tool that analyzes text for polarity, from negative to positive. With the help of sentiment analysis, onne can get the nature of opinion that is being reflected in documents, newsfeeds, social media tweets, etc.

The dataset used in this project is got from the **janeaustenr** package.Sentiment lexicons contained in the **tidytext** package, available in the **sentiment** dataset is used in order to build this project.

```{r}
library(tidytext)
sentiments
```

The **bing** lexicon model classifies the sentiment into a binary category of negative and positive.
```{r}
get_sentiments("bing")
```

The **janeaustenr** package will provide us with the textual data in the form of books authored by the novelist **Jane Austen**. **Tidytext** will allow us to perform efficient text analysis on our data.
```{r}
library(janeaustenr)
library(stringr)
library(dplyr)
tidy_data <- austen_books() %>%
 group_by(book) %>%
 mutate(linenumber = row_number(),
   chapter = cumsum(str_detect(text, regex("^chapter [\\divxlc]", 
                          ignore_case = TRUE)))) %>%
ungroup() %>%
unnest_tokens(word, text)
```
Having performed the tidy operation on the text such that each row contains a single word, the **bing** lexicon will be used and **filter()** will be implemented over the words that correspond to **joy**
The book Sense and Sensibility will be used and its words will be derived to immplement out sentimen analysis model.
```{r}
positive_sentiments <- get_sentiments("bing") %>%
 filter(sentiment == "positive")

tidy_data %>%
 filter(book == "Emma") %>%
 semi_join(positive_sentiments) %>%
 count(word, sort = TRUE)
```

Shown from the above result, it is observed that there are many positive words like **good**, **happy**, **love** etc. In the next step, the **spread()** function will be used to segregate the data into separate columns of positive and negative sentiments. The **mutate()** function will be used to calculate the total sentiment, that is, the difference between positive and negative sentiment.

```{r}
library(tidyr)
bing <- get_sentiments("bing")
Emma_sentiment <- tidy_data %>%
 inner_join(bing) %>%
 count(book = "Emma" , index = linenumber %/% 80, sentiment) %>%
 spread(sentiment, n, fill = 0) %>%
 mutate(sentiment = positive - negative)
```

The next step shows the visualization of the words present in the book **Emma** based on their corresponding positive and negative scores
```{r}
library(ggplot2)

ggplot(Emma_sentiment, aes(index, sentiment, fill = book)) +
 geom_bar(stat = "identity", show.legend = TRUE) +
 facet_wrap(~book, ncol = 2, scales = "free_x")
```

Counting the most common positive and negative words that are present in the novel.
```{r}
counting_words <- tidy_data %>%
 inner_join(bing) %>%
 count(word, sentiment, sort = TRUE)
head(counting_words)
```
The next step involves visualization of the sentiment scores

```{r}
counting_words %>%
 filter(n > 150) %>%
 mutate(n = ifelse(sentiment == "negative", -n, n)) %>%
 mutate(word = reorder(word, n)) %>%
 ggplot(aes(word, n, fill = sentiment))+
 geom_col() +
 coord_flip() +
 labs(y = "Sentiment Score")
```

The final visualization shows a **wordcloud** that will delineate the most recurring positive and negative words.

```{r}
library(reshape2)
library(wordcloud)
tidy_data %>%
 inner_join(bing) %>%
 count(word, sentiment, sort = TRUE) %>%
 acast(word ~ sentiment, value.var = "n", fill = 0) %>%
 comparison.cloud(colors = c("red", "dark green"),
          max.words = 100)
```

